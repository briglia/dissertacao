\documentclass[12pt,brazil,a4paper]{report}
\usepackage[top=3cm,left=3cm,right=2cm,bottom=2cm]{geometry}
%\usepackage{sbc2003}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{boxedminipage}
%\usepackage{epsf}
\usepackage[latin1]{inputenc}
\usepackage{babel}
\usepackage{graphicx}
\usepackage{setspace}

\begin{document} 

\thispagestyle{empty}

\begin{center}
\begin{Large}
Anderson Farias Briglia \\
Orientador: Dr. Edward David Moreno\\
Co-orientador: Dr. Raimundo Barreto\\
\end{Large}
\end{center}

\vspace {3.8 cm}

\begin{center}
\begin{huge}
Mapas Auto-organizáveis na Compressão de Memória Cache em Sistemas Embarcados
\end{huge}
\end{center}

\vspace {3.8 cm}

\begin{flushright}
\begin{minipage}[t]{9 cm}
Dissertação apresentada ao Departamento de Ciência da Computação do Instituto de Ciências Exatas da Universidade Federal do Amazonas, como requisito parcial para obtenção do título de Mestre em Informática.
\end{minipage}
\end{flushright}

%\vspace {3.8 cm}
\vspace {4 cm}

\begin{center}
%\begin{Large}
Manaus \\
Março de 2008\\
%\end{Large}
\end{center}

\newpage

\tableofcontents
\listoffigures
\listoftables

\newpage

\onehalfspacing

\chapter{Introdução}
%\section {Introdução}
\label{sec:introducao}
A grande maioria dos sistemas embarcados têm como principal característica seu uso para uma tarefa específica, porém, existem sistemas embarcados que não necessariamente são específicos \cite{mor00}. Como é o caso do sistema operacional \textit{Linux} analisado nesta dissertação de mestrado. O avanço da minituarização dos componentes eletrônicos e a queda do preço dos equipamentos, fez com que o poder de processamento de um PDA (\textit{Personal Data Assistance}), por exemplo, caísse consideravelmente, permitindo que esse tipo de dispositivo possa ter sistemas embarcados mais sofisticados.\\

Com o poder de processamento dos dispositivos móveis aumentando, as aplicações disponíveis aos usuários acompanham este crescimento e se tornam mais complexas. Como características inerentes de qualquer sistema embarcado, pode-se citar o processamento limitado, consumo de energia bem restrito e problemas relacionados à memória disponível para as aplicações. Nesta dissertação, uma possível solução para o problema de memória dos sistemas embarcados é proposta e analisada. Possíveis soluções para o problema de consumo de potência ou aumento do poder de processamento dos sistemas embarcados, não é o foco deste trabalho.\\

Segundo \cite{castro03}, uma das possíveis soluções para o problema de escassez de memória nos sistemas embarcados é a utilização de algoritmos de compressão. A compressão tem se mostrado uma técnica eficiente para otimizar o uso da memória em sistemas embarcados\cite{briglia07, castro03, douglis93, irina05, kaplan99compressed}. Ela também tem sido utilizada como um meio de melhorar o uso da memória cache, reduzindo assim o consumo de potência e melhorando a performance do sistema de memória, visto que a memória cache é, geralmente, mais rápida do que a memória principal de um computador ou de um dispositivo móvel. E sendo uma memória de acesso rápido, o processador gasta menos tempo para acessá-la, beneficiando também o consumo de potência total do sistema.\\

O \textit{Cache} Comprimido (CC) é uma técnica que adiciona um novo nível na hierarquia de memória do Linux \cite{castro03, douglis93, kaplan99compressed}. O CC é usado para aprimorar o tempo de acesso às páginas de memória no \textit{kernel} (ou núcleo) do Linux, armazenando mais páginas na memória RAM (\textit{Random Access Memory}), e reduzindo o número de páginas que vão para a área de \textit{swap}\footnote{Área de swap é uma área reservada no sistema de arquivos do Sistema Operacional, afim de ser utilizada como uma extensão de memória principal.} ou que seriam descartadas caso o sistema não a possuísse. É sabido que a área de \textit{swap}, em geral, é muito mais lenta que a memória principal, e custosa com relação ao consumo de energia pois na maioria dos casos está associada a dispositivos de bloco, como por exemplo, um disco rígido. E ainda tem-se o problema de que em sistemas embarcados geralmente essa área não está presente ou n\~{a}o possui o tamanho ideal.\\

Na implementação usada neste trabalho, o tamanho da área de CC possui influência na quantidade de memória disponível para as aplicações. Se o tamanho do CC, ou seja, da memória alocada para ele, for muito grande, podem ocorrer situações de falta de memória, ocasionando em travamento do sistema ou das aplicações que estão sendo executadas no momento. Hoje, a escolha de um tamanho para o CC é empírica. Ou seja, é escolhido um tamanho baseado em experimentos (como os vistos nas seções posteriores deste trabalho), ou simplesmente na estimativa de memória total livre após a alocação do CC. Um cenário ideal para calcular o tamanho do CC é que o perfil das aplicações, ou melhor, das alocações de memória das aplicações, seja levando em conta quando o tamanho for escolhido.\\

Como forma de estimar o comportamento da memória, alinhando assim o tamanho do CC a ser utilizado com a forma de como as aplicações utilizam a memória, é utilizado o trabalho de mestrado de Maurício Lin \cite{Alecrim:07, Mlin:06}. Neste trabalho foi implementado um esquema de classificação de padrões de consumo de memória utilizando Mapas Auto-Organizáveis (do inglês SOM: \textit{Self-Organized Maps}). Basicamente é feito um ``mapa'' de como a memória foi utilizada por determinada aplicação. Nesta dissertação de mestrado, esse mapa é utilizado como entrada para a ferramenta que irá calcular o tamanho do CC, baseado no perfil das aplicações testadas.

\section {Motivação}
\label{sec:motivacao}

A memória é um dos componentes críticos que possuem maiores restrições quando usada em sistemas embarcados. Por outro lado, os sistemas têm sido aperfeiçoados através de técnicas sofisticadas, algoritmos complexos e suporte a tempo-real. Como consequência, as aplicações para sistemas embarcados têm se tornado maiores e com um volume de dados manipulados sempre crescente.\\

Dado esse cenário, é muito importante definir mecanismos que aperfeiçoem a utilização de memória e/ou a performance das aplicações quando estas fazem uso intenso da memória do dispositivo.\\

Em \cite{castro03}, foi implementada uma versão do Cache Comprimido Adaptativo para a versão 2.4.x do \textit{kernel} do Linux. Os mecanismos de falta de memória encontrados na versão 2.4.x são diferentes do que temos hoje (ex. mapeamento de páginas anônimas, Out-of-memory killer, etc), nas versões mais atuais (2.6.x, por exemplo).\\

Um ponto motivacional deste trabalho é a realização de uma implementação do Cache Comprimido Adaptativo para as versões mais atuais do \textit{kernel} do Linux, disponibilizando assim seu uso em dispositivos móveis mais atuais, baseados neste sistema operacional. A implementação usada neste trabalho está em desenvolvimento \cite{ccache09}, e a idéia desta dissertação é contribuir nesse projeto \textit{Open Source}, além de melhorar o desempenho das aplicações quando executadas em ambiente de Linux embarcado, propondo uma nova metodologia de gerenciamento de memória no \textit{kernel} do Linux.\\

Na versão do Cache Comprimido Adaptativo apresentada em \cite{ccache09}, não foi utilizada nenhuma técnica para estimar o comportamento do tamanho da memória comprimida. A escolha de uma heurística inadequada pode impactar no desempenho de todo o sistema, pois a relação memória comprimida X memória não-comprimida é muito importante quando se trata de adaptatividade. Estudos realizados anteriormente em \cite{castro03}, mostram que uma escolha errada no tamanho da memória comprimida pode criar \textit{overheads} desnecessários ao sistema, acarretando em perda de performance. Assim, a implementação de um esquema de adaptatividade utilizando SOM se torna um outro ponto de motivação do trabalho.

\section{Objetivos}
\label{sec:objetivos}

O propósito principal deste trabalho é desenvolver um sistema de memória comprimida, utilizando como base a implementação \textit{Open Source} encontrada em \cite{ccache09}, e que implemente o conceito de adaptatividade do tamanho do CC, baseado em perfis de aplicações, definidos utilizando SOM's.\\

Experimentos realizados em trabalhos anteriores \cite{briglia07, castro03}, indicaram que o tamanho da área comprimida de memória afeta o desempenho do sistema. Espera-se que, seja possível classificar o uso da memória, como mostrado em \cite{Mlin:06} e utilizar esses dados na heurística de como a área de cache comprimido deve ser dimensionada. A implementação deste trabalho não possui dependências de arquitetura, apesar de ser focada em Linux embarcado para arquitetura ARM (\textit{Advanced RISC Machine}).\\

A área para memória comprimida será adicionada ao sistema existente como mostrado na Figura \ref{fig:cc_intro}.

\begin{figure}[ht]%htbp
\centering
\includegraphics[scale=0.85]{cc-intro}
\caption{Hierarquia de memória com cache comprimido}
\label{fig:cc_intro}
\end{figure}

A versão do \textit{kernel} utilizada é a 2.6.x, e como resultado prático final um \textit{patch} ou uma série de \textit{patches} serão gerados, com modificações relativas à implementação do CC para a última versão do \textit{kernel} disponível. Uma aplicação que extrai os dados providenciados pelo SOM durante a classificação do uso da memória, será implementada. Essa aplicação exportará os dados necessários (como os perfis de consumo de memória de aplicações escolhidas), para o ajuste do tamanho do CC. Na Seção \ref{sec:classe_rede} é apresentada a forma de como os padrões de memória são classificados.\\

Para a validação da implementação, são utilizados dois tipos de testes preliminares: \textit{benchmarks} sintéticos e testes com casos de uso que simulam a utilização real do sistema, utilizando aplicações gráficas tais como: navegador \textit{Web}, leitor de arquivos PDF, tocador de áudio e vídeo. Nos testes com \textit{benchmarks} sintéticos, foram utilizados suites como o MemTest \cite{memtest06} e o MiBench \cite{GRE01}. O MemTest foi utilizado nos testes de performance pois sua principal característica é a realização de operações com a memória virtual do Sistema Operacional, mais especificamente, com alocações e desalocações de porções de memória. O MiBench é bastante utilizado como benchmarking de sistemas embarcados e provê um conjunto de módulos que podem ser utilizados como \textit{benchmarking} tanto para medidas relacionadas à arquitetura de \textit{hardware} quanto medidas com operações de memória, ou operações multimídia. Basicamente os testes usando essas ferramentas fazem um uso intenso da memória RAM. No caso dos testes utilizando casos de uso, é utilizada uma ferramenta de automação chamada XAutomation \cite{xauto07}, para criar uma interação com o ambiente gráfico do sistema, simulando um uso real das aplicações mencionadas anteriormente, enquanto dados referentes à utilização da memória cache comprimida são armazenados. Com estes dois tipos de testes, espera-se ter dados suficientes para apontar o impacto da utilização de compressão da memória utilizando SOM, com a heurística para adaptar o tamanho da memória comprimida.

\section{Cronograma}
%\label{sec:cronograma}
%O trabalho aqui proposto é dividido em etapas distintas conforme detalhadas nos itens seguintes. O cronograma apresentado possui informações para as etapas passadas e futuras do projeto.\\\\

%\textbf{Cronograma de 2007:}
%\begin{enumerate}
%\item Levantamento Bibliográfico - Coleta, organização e análise da literatura técnica relacionada com os assuntos abordados no trabalho.
%\item Implementação do Cache Comprimido sem adaptatividade - Implementação do Cache Comprimido para Linux embarcado \cite{ccache09}.
%\item Testes com o CC atual - Preparação do dispositivo móvel e da suite de testes.
%\item Artigo para OLS2007 - Escrita do artigo com detalhes de implementação e dos testes para o Linux Symposium 2007.
%\item Preparação da proposta - Revisão da bibliografia e dos trabalhos relacionados.
%\end{enumerate}
% 
% \vspace{\baselineskip}
% 
% \newlength{\constlen}
% \newlength{\pllen}
% \setlength{\constlen}{7mm}
% \newcommand{\mkp}[1]{\makebox[\constlen]{#1}}
% 
% \newcommand{\putobj}[3]{
% \setlength{\unitlength}{1mm}
% \begin{picture}(0,0)
% \put(#1,#2){#3}
% \end{picture}}
% \newcommand{\pl}[1]{\setlength{\pllen}{#1\constlen}\putobj{0}{0}{\rule[0.3mm]{\pllen}{2mm}}}
% 
% \setlength{\tabcolsep}{0pt} %largura entre separadores das colunas
% \renewcommand{\arraystretch}{1.25} %altura das colunas
% 
% \begin{table}[ht]
%     \centering
% \begin{tabular}{|l|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|}
% \hline
% \makebox[5cm]{Tarefas} &
% \multicolumn{1}{c|}{Jan} &
% \multicolumn{1}{c|}{Fev} &
% \multicolumn{1}{c|}{Mar} &
% \multicolumn{1}{c|}{Abr} &
% \multicolumn{1}{c|}{Mai} &
% \multicolumn{1}{c|}{Jun} &
% \multicolumn{1}{c|}{Jul} &
% \multicolumn{1}{c|}{Ago} &
% \multicolumn{1}{c|}{Set} &
% \multicolumn{1}{c|}{Out} &
% \multicolumn{1}{c|}{Nov} &
% \multicolumn{1}{c|}{Dez} \\
% \hline
% \hline
% Levantamento Bibliográfico &\pl{5} & & & & & & & &\pl{3} & & &  \\
% \hline
% Implementação do CC s/ adapt. & & & &\pl{5} & & & & & & & &\\
% \hline
% Testes com o CC atual & & &\pl{3} & & & & & & & & & \\
% \hline
% Artigo para OLS2007 & & &\pl{4} & & & & & & & & & \\
% \hline
% Preparação da proposta & & & & & & & & & & &\pl{2} &\\
% \hline
% \end{tabular}
%     \caption{Cronograma de trabalho em 2007.}
%     \label{tab:cronograma}
% \end{table}
% 
% \textbf{Cronograma para 2008:}
% \begin{enumerate}
% \item Preparação da proposta - Revisão da bibliografia, dos trabalhos relacionados e escrita da proposta.
% \item Testes com SOM - Baseado em \cite{Alecrim:07, Mlin:06}, fazer os testes e obter os primeiros resultados utilizando a última versão do Linux embarcado para o dispositivo móvel alvo.
% \item Avaliação dos testes com SOM - Verificar os perfis de consumo de memória coletados no item anterior.
% \item Implementação do CC com adaptatividade - Implementação de modificações na versão atual do CC para a utilização de adaptatividade.
% \item Integração SOM e CC - Implementação de uma ferramenta que avalie os mapas resultantes da avaliação dos vários perfis de memória, e o Cache Comprimido. A idéia é utilizar a saída dessa ferramenta como entrada para a heurística de adaptatividade do CC.
% \item Testes Finais - Testes com a versão do CC com adaptatividade utilizando SOM's.
% \item Confecção da dissertação - Escrita da dissertação de mestrado.
% \item Revisão Final - Revisão da implementação e da dissertação.
% \end{enumerate}
% 
% \begin{table}[ht]
%     \centering
% \begin{tabular}{|l|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|p{\constlen}|}
% \hline
% \makebox[5cm]{Tarefas} &
% \multicolumn{1}{c|}{Jan} &
% \multicolumn{1}{c|}{Fev} &
% \multicolumn{1}{c|}{Mar} &
% \multicolumn{1}{c|}{Abr} &
% \multicolumn{1}{c|}{Mai} &
% \multicolumn{1}{c|}{Jun} &
% \multicolumn{1}{c|}{Jul} &
% \multicolumn{1}{c|}{Ago} &
% \multicolumn{1}{c|}{Set} &
% \multicolumn{1}{c|}{Out} &
% \multicolumn{1}{c|}{Nov} &
% \multicolumn{1}{c|}{Dez} \\
% \hline
% \hline
% Preparação da Proposta &\pl{2} & & & & & & & & & & &  \\
% \hline
% Testes com SOM & & &\pl{2} & & & & & & & & &\\
% \hline
% Avaliação dos testes & & &\pl{1} & & & & & & & & & \\
% \hline
% Implementação do CC com adaptatividade & & & &\pl{3} & & & & & & & & \\
% \hline
% Integração SOM e CC & & & & &\pl{3} & & & & & & &\\
% \hline
% Testes Finais & & & & & &\pl{2} & & & & & &\\
% \hline
% Confecção da dissertação & & & & & & &\pl{4} & & & & &\\
% \hline
% Revisão Final & & & & & & & & & & &\pl{2} &\\
% \hline
% \end{tabular}
%     \caption{Cronograma de trabalho para 2008.}
%     \label{tab:cronograma}
% \end{table}

\section{Organização da dissertação}

O Capítulo 1 trata da introdução, motivação e objetivos desse trabalho. Neste capítulo o leitor será apresentado ao problema e à solução proposta pelo autor.\\

O Capítulo 2 descreve o estado atual da implementação do Cache Comprimido utilizada neste trabalho. Detalhes de implementação e testes também são descritos e discutidos.\\

O Capítulo 3 apresenta o trabalho realizado em \cite{Alecrim:07} e \cite{Mlin:06}. Estes trabalhos propõem uma classificação de padrões de consumo de memória utilizando redes neurais e mapas auto-organizáveis.\\

O Capítulo 4 apresenta a solução proposta de um Cache Comprimido Adaptativo que utilize SOM's para classificar os padrões de consumo de memória das aplicações. Neste capítulo o leitor encontrará detalhes de como a heurística de adaptatividade funciona com os dados providos pelas redes treinadas do SOM. Testes e resultados também são apresentados.\\

No Capítulo 5 os testes realizados no capítulo 4 são discutidos e analisados. Os impactos e as melhorias da solução proposta são criticados e comparados com resultados de trabalhos relacionados.\\

No Capítulo 6 são apresentadas as conclusões com base nos resultados dos capítulos anteriores. Também são apresentados alguns trabalhos futuros e propostas de melhorias para a versão do Cache Comprimido implementada neste trabalho.

\chapter{Cache Comprimido}
\section{Estado Atual da Pesquisa}
\label{sec:pesquisa}

Esta seção tem o propósito de apresentar os estudos e as pesquisas realizadas até o momento e que são requisitos relevantes para o desenvolvimento da proposta descrita na Seção \ref{sec:objetivos}.\\

Inicialmente é apresentado o estado da arte, onde alguns trabalhos relacionados são analisados. Em seguida, a atual implementação do CC é discutida, para a versão 2.6.x do \textit{kernel} do Linux encontrada em \cite{ccache09}. Também são exibidos e descritos alguns testes realizados com essa versão e apresentados em \cite{briglia07}.

\subsection{A memória virtual do Linux}

Páginas físicas são a unidade básica do gerenciamento de memória \cite{love05kerneldevel} e o MMU (\textit{Memory Management Unit} é o hardware responsável por traduzir endereços virtuais em reais das páginas de memória, e vice-versa. \\

No gerenciamento da memória virtual, duas listas do tipo LRU (\textit{Last Recently Used}) são utilizadas afim de classificar as páginas: LRU para páginas ativas e uma LRU para páginas inativas. Quando o sistema precisa alocar novas páginas, elas são inicialmente retiradas da lista LRU de páginas inativas. O algoritmo responsável por selecionar e liberar as páginas é chamado de \textit{Page Frame Reclaiming Algorithm} - PFRA.\\

Afim de identificar cada tipo de página, \textit{flags} são utilizadas na estrutura de dados que as implementam. Para diferenciar as páginas comprimidas das páginas comuns, a implementação atual do Cache Comprimido adiciona uma \textit{flag} na estrutura de dados da página.\\

Quando o sistema está sob pressão de memória, ou seja, há menos memória disponível que o necessário, o PFRA libera as páginas de acordo com a sua classificação:

\begin{itemize}
\item Páginas do \textit{Swap-cache} são escritas na área de \textit{swap} disponível.

\item Páginas "sujas" do \textit{Page cache} são escritas no \textit{filesystem} utilizando o procedimento específico de escrita.

\item Páginas "limpas" do \textit{Page Cache} são simplesmente liberadas da memória, e ficam disponíveis para serem utilizadas novamente por outros processos.
\end{itemize}

\subsubsection{O Swap Cache}

Este é o cache para páginas anônimas. Toda as páginas do \textit{swap cache} são parte de um único \textbf{swapper\_space}, a estrutura que agrupa todas as páginas que podem ir para a área de \textit{swap}. Uma outra estrutura de dados, chamada \textit{radix tree} é utilizada para manter todas as páginas do \textit{Swap cache} e torna a busca por páginas muito mais eficiente. O campo \textbf{swp\_entry\_t} da estrutura de dados da área de \textit{swap} é utilizado como chave-de-busca quando uma página do \textit{swap cache} é procurada. Esta estrutura é usada para identificar onde a página requisitada se encontra no dispositivo de bloco utilizado pelo seu \textit{swap}.

\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.8]{swp_entry}
	\caption{Campos da estrutura \texttt{swp\_entry\_t}}
	\label{fig:swp_entry_fields}
\end{figure}

Na Figura \ref{fig:swp_entry_fields}, \textbf{`type'} identifica em qual área de \textit{swap} a página de se encontra. No sistema operacional Linux, podem haver até 32 \textit{swaps} simultâneos.

\subsubsection{O Page Cache}
Este é o cache utilizado para armazenar as páginas do \textit{filesystem}. Ou seja, todo arquivo aberto pelas aplicações possui páginas de memória alocadas e armazenadas no \textit{Page Cache}. Assim como o \textit{Swap Cache}, este \textit{cache} também possui uma \textit{radix tree} que armazena as referências, ou melhor, os ponteiros para as páginas de um determinado arquivo presente no sistemas de arquivos, que esteja sendo utilizado. O valor de \textit{offset} dentro do arquivo é utilizado como chave-de-busca para localizar tais páginas. Cada arquivo aberto possui uma \textit{radix tree} própria, com os nodos da árvore apontando para as páginas pertencentes ao arquivo.

\subsection{Cache Comprimido}
Em um sistema com cache comprimido, a memória é dividida em duas grandes porções: memória comprimida e não-comprimida \cite{castro03-2, douglis93, kaplan99compressed}. A área de memória comprimida geralmente é alocada onde antes existia memória não-comprimida. A relação dos tamanhos da memória comprimida e não-comprimida deve ser avaliada pois os dois tamanhos interferem em como cada porção de memória se comporta, dependendo do \textit{workload} imposto pelas aplicações.\\

Muitos pesquisadores \cite{kaplan99compressed, irina05} têm investigado o uso de compressão para reduzir as operações de \textit{paging}, introduzindo um novo nível na hierarquia de memória. Armazenar as páginas de memória em uma área comprimida, naturalmente aumenta o tamanho efetivo da memória e também diminui o acesso à dispositivos de memória secundária \cite{castro03}, que é muito mais lenta que a principal. Apesar dessa diferença de velocidade entre a memória principal e a memória secundária ser grande, quando se leva em conta os sistemas embarcados, ela é menor. Geralmente, os sistemas embarcados não possuem memória secundária armazenada em um disco rígido, outros dispositivos são utilizados nesse caso. Memórias do tipo \textit{compact flash} e cartões MMC, são os principais dispositivos encontrados hoje no mercado que são utilizados como memória secundária em dispositivos móveis \footnote{A velocidade de leitura de um cartão MMC comum, chega à taxa de 416 Mbits/seg \cite{mmca}. A velocidade das memórias RAM's variam, mas as mais comuns possuem um tempo de acesso de 80-90 ns.}. Mesmo tendo a diferença de velocidade de acesso entre a memória principal e a secundária menor, os sistemas embarcados possuem um grande requisito relacionado ao tamanho dessa memória. Assim, o uso de compressão é justificado pois, como será discutido posteriormente, é capaz de aumentar o tamanho efetivo da memória disponível para as aplicações.\\

As abordagens de cache comprimido baseadas em \textit{software}, ou seja, aquelas que não propõem alteração de \textit{hardware}, podem ser estáticas ou dinâmicas. As abordagens estáticas \cite{swapcc99, wilson99, crames05} são caracterizadas por não possuírem uma heurística de redimensionamento do cache comprimido, diferente das abordagens dinâmicas. Nesse segundo tipo, existe um algoritmo que determina quando o cache comprimido deve alterar seu próprio tamanho, geralmente baseado no \textit{workload} da memória.\\

Os primeiros estudos que utilizavam cache comprimido para reduzir a paginação em disco, ou seja, a quantidade de acessos de leitura/escrita, foram feitos por Appel e Li \cite{li91} e Paul R. Wilson \cite{wilson91}, em 1991. Outro pesquisador, chamado Douglis\cite{douglis93}, obteve algumas melhorias na performance do sistema, usando uma implementação de cache comprimido adaptativo no sistema operacional Sprite. Porém, Douglis não conseguiu concluir se o uso de cache comprimido é útil ou não pois seus testes apresentaram resultados divergentes, com melhorias em alguns casos e pioras em outros.\\

Tendo o trabalho de Douglis ser inconclusivo, muitos outros pesquisadores se ocuparam em estudar o caso. Em 1999, Kaplan\cite{kaplan99compressed} chegou à conclusão que a compressão do cache pode reduzir os custos das operações de \textit{paging}\footnote{São operações de E/S no \textit{Page Cache}\cite{love05kerneldevel}. Este cache é utilizado para reduzir o número de E/S dos discos, aumentando assim a performance. Páginas do \textit{Page Cache} estão na memória RAM.}. Kaplan ainda confirmou o que Douglis\cite{douglis93} verificou anteriormente: cache comprimido estático beneficia menos do que um cache comprimido com adaptatividade. Alguns trabalhos correlatos também foram desenvolvidos em 1999. Como apresentado em \cite{swapcc99}, não se trata especificamente da memória cache comprimida, mas sim da compressão da área de \textit{swap} do sistema. Neste trabalho é apresentada uma versão de compressão da memória voltada às páginas que podem ser selecionadas para o \textit{swap}, salvando algum espaço no disco e diminuindo as operações de E/S no \textit{swap}. Testes concluíram que a compressão da área de \textit{swap} pode aumentar a velocidade das aplicações em 20\%. Outros trabalhos também apontaram ganhos na performance de aplicações, como apresentado em \cite{irina05}, no quais a compressão da memória melhorou a performance de aplicações reais, com índices de 1.3 a 55. Nos testes com \textit{benchmarks} e algumas aplicações de simulação, como o NS2 (\textit{Network Simulator}), foi verificado que um nível de memória comprimida adicionada ao sistema garante que aplicações que necessitem de um \textit{working set} maior que a memória física disponível, possam ser executadas.\\

Um dos últimos trabalhos sobre Cache Comprimido foi implementado por Rodrigo Castro \cite{castro03-2, castro03}. Utilizando a versão 2.4.x do Linux \textit{kernel}, vários testes foram realizados, com adaptatividade e sem. Os resultados mostraram que os ganhos são maiores quando existe alguma heurística de adaptatividade presente no CC. Como dito anteriormente, um dos objetivos deste trabalho também é propor uma heurística de adaptatividade para o CC. Porém, pretende-se usar um método mais científico e menos empírico. Através dos SOM's e da classificação de padrões de consumo de memória proposta em \cite{Mlin:06}, espera-se traçar um ``perfil'' de consumo de cada aplicação e usá-lo para definir uma heurística de adaptatividade do CC.\\

A maioria dos trabalhos discutidos anteriormente, são anteriores às versões mais novas do \textit{kernel} do Linux. Daquela época para os dias atuais, o \textit{kernel} sofreu muitas melhorias e o esquema utilizado para o CC na versão usada nesse trabalho é diferente. Assim faz-se necessário um \textit{overview} da versão do Cache Comprimido usada neste trabalho, implementada por Nitin Gupta \cite{briglia07, ccache09}.

\subsection{Cache Comprimido para Linux \textit{kernel} 2.6.x}

Dados experimentais avaliados em um sistema utilizando Cache Comprimido \cite{briglia07}, mostram que não só as taxas de E/S podem ser melhoradas, como também todo o comportamento do sistema, especialmente em situações de memória crítica, como por exemplo, adiando a chamada do \textit{Out-Of-Memory killer} -- OOM.\\

A implementação atual do Cache Comprimido tira vantagem do sistema de \textit{swap}, adicionando uma área de \textit{swap} virtual como área de armazenamento das páginas comprimidas. Utilizando o algoritmo de compressão usando em sistemas JFFS2 (LZO \cite{obe05lzo, ZivLem77}), páginas alocadas na memória selecionadas para irem para o \textit{swap} são comprimidas e enviadas à uma partição de swap virtual através de um dispositivo virtual de bloco chamado \textit{ramzswap}. Basicamente, o \textit{ramzswap} "engana" o \textit{kernel} do Linux e faz com que seja adicionada uma área de \textit{swap}, que na realidade não é uma partição em um disco, mas sim uma área da memória RAM do dispositivo. O tamanho da memória alocada para essa área é o tamanho do Cache Comprimido.\\

\begin{figure}[htb]
 \centering
 \includegraphics[scale=0.7]{compcache.png}
 % compcache.png: 425x122 pixel, 72dpi, 14.99x4.30 cm, bb=0 0 425 122
 \caption{Estrutura de swaps utilizando ramzswap como dispositivo de swap virtual.}
 \label{fig:compcache}
\end{figure}

\subsubsection{Design da Implementação}

Utilizando um dispositivo virtual de bloco como partição para \textit{swap}, o Cache Comprimido usado neste trabalho aproveita todo o mecanismo de \textit{swapping} implementado no \textit{kernel} do Linux. Dessa forma, o \textit{Swap Cache} (discutido anteriormente), assim como a seleção de páginas para serem comprimidas, são utilizadas de forma natural pelo algoritmo de Gerenciamento de Memória do \textit{kernel} do Linux.\\

Afim de obter maior eficiência e evitar alguns problemas como a fragmentação, foi desenvolvido um escalonador de memória especialmente para o Cache Comprimido. Esse escalonador, chamado xvMalloc\cite{ccache09}, é baseado no escalonador TLSF (\textit{Two Level Segregate Fit})\cite{Masmano04}, desenvolvido para sistemas de tempo real.\\

O xvMalloc foi desenvolvido levando em conta que os alocadores de memória de propósito geral, geralmente são projetados para trabalharem com requisições em número de páginas maiores que 4 \textit{kilobytes}, que é o tamanho padrão para páginas de memória no Linux. Dessa forma, quando utilizados para alocarem porções muito menores, como 32 \textit{bytes} ou $3/4$ do tamanho de uma página, não se obtém uma boa performance e muitas vezes acontece a fragmentação.\\

Herdadas do TLSF\cite{Masmano04}, o xvMalloc\cite{ccache09} possui algumas características que são muito úteis para o Cache Comprimido:

\begin{itemize}
 \item \textbf{Tempo de resposta constante:}\cite{Masmano04} O pior caso de tempo de execução (WCET) do xvMalloc (e do TLSF), para alocar e desalocar uma porção de memória é constante, ou seja, $O(1)$.
 \item \textbf{Eficiência no consumo de memória:}\cite{Masmano04} TLSF vem sido testado em várias situações de consumo de memória, em sistemas operacionais de tempo-real e 
 \item \textbf{Tamanho dos metadados:}\cite{ccache09} em um sistema de 64 bits, o xvMalloc gasta somente 4 bytes por objeto são necessários para localizá-lo e guardar outras informações imprescendíveis.
 \item \textbf{Tamanho do objeto:}\cite{ccache09} Cada objeto (que contém uma página comprimida, ou uma parte dela), possui seu tamanho exato armazenado no cabeçalho, economizando assim mais 2 bytes por objeto. O xvMalloc ainda possui um método chamado \textit{xvGetObjectSize(obj)} que retorna o tamanho do objeto comprimido, esse método é utilizado pelo decompressor.
\end{itemize}

Essas características são importantes para o Cache Comprimido pois são muito utilizadas pelo sistema proposto. Sendo o \textit{ramzswap} nada mais que uma área de memória, é importante que a velocidade de leitura/escrita (nessa caso, de alocação e liberação), seja tão rápida quanto o acesso a uma partição de swap real. A baixa fragmentação da memória também é importante pois no caso do Cache Comprimido, estamos falando de porções de memória que podem ser muito menos que o tamanho padrão de uma página (que é de 4 KB, no Linux). Assim, como as páginas de memória possuem tamanhos bastante variados, é importante utilizar técnicas que garatem uma baixa fragmentação, melhorando assim a velocidade na recuperação de páginas comprimidas ou na liberação de espaços vazios.\\

Na versão do Cache Comprimido, apresentada em \cite{briglia07}, o tamanho dos metadados era um problema pois gastava-se muitos bytes para endereçar e guardar as informações das páginas comprimidas. Na versão mais atualizada, usada nesse trabalho, os metadados gastos para endereçar as páginas comprimidas ou para indicar espaços vazios na memória, sofreram alterações e a estrutura dos objetos é discutida na próxima seção.

%Quando uma página está para ser comprimida, o nodo da árvore radix que está apontando para a página tem sua referência trocada, apontando para um \textit{chunk\_head}. Por sua vez, a estrutura \textit{chunk\_head} possui todas as informações para encontrar os outros \textit{chunks} e assim recuperar a página comprimida: tamanho da página comprimida, algoritmo usado na compressão, localização do primeiro \textit{chunk}, etc.\\

%Um dos problemas encontrados com essa abordagem é o tamanho dos metadados, ou seja, das estruturas responsáveis por todo o manuseio de \textit{chunks} e páginas comprimidas. Uma página comprimida que esteja dividida em 3 \textit{chunks}, ocupa 84 bytes de memória com os metadados\footnote{Fazendo as contas: 3 \textit{chunks} necessitam de \texttt{sizeof(chunk\_head) + 3 * sizeof(chunk)}.}. Isso é bastante espaço, levando em consideração que estamos falando em 1 página comprimida. Um outro problema é que o princípio de localidade não é obedecido quando uma página comprimida é extraída. Isso leva a um \textit{overhead} de leitura da página, já que ela pode ser recuperada de várias páginas físicas (ou \textit{page frames}).\\

%Quando uma página é requisitada, uma operação de \textit{lookup} é realizada na árvore radix do page-cache. Se esta operação retornar um \textit{chunk\_head}, significa que a página é comprimida e está dividida em vários \textit{chunks} de tamanho menor que \texttt{PAGE\_SIZE}. Como o \textit{chunk\_head} possui um ponteiro para o primeiro \textit{chunk} da lista de \textit{chunks} da página, é possível recuperar todos os \textit{chunks}, pois os mesmos fazem parte de uma lista encadeada. Após todos os \textit{chunks} serem recuperados, a página pode ser descomprimida e um ponteiro para ela é passado à função de \textit{lookup}. Esta sequência de operações será detalhada nas seções posteriores deste trabalho.

\subsubsection{Armazenamento das Páginas Comprimidas}

As páginas comprimidas são armazenadas em estruturas de dados que o xvMalloc gerencia. Essas estruturas são projetadas de modo que se agrupem as páginas de memória que estão livres.\\

O cabeçalho dos objetos que o xvMalloc manipula está representado na figura \ref{fig:obj-header}.

\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.7]{obj-header.png}
	\caption{Cabeçalho de um objeto manipulado pelo alocador do Cache Comprimido -- xvMalloc.}
	\label{fig:obj-header}
\end{figure}

Onde, cada campo significa:\\

\begin{itemize}
 \item \textit{Size}: tamanho da página comprimida, passado para o xvMalloc pelo compressor.
 \item Prev: offset para a posição do bloco anterior (usado ou livre), relativo ao início do \textit{page frame}.
 \item \textit{Flags}:
	\begin{itemize}
		\item F1: 1 se o bloco estiver usado 0, caso contrário.
		\item F2: 1 se o bloco anterior estiver usado 0, caso contrário.
	\end{itemize}
 \item PAD: Não utilizado se o alinhamento for de 4 bytes.
\end{itemize}

O tamanho da estrutura de dados que representa um cabeçalho de uma página comprimida ou porção dela é de 4 bytes.\\

Para objetos que estão livres, ou seja, podem ser alocados pelo alocador xvMalloc para comportar uma página comprimida, ou uma porção dela, a estrutura de dados que os representa é mostrada na figura \ref{fig:obj-free}.

\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.7]{obj-free.png}
	\caption{Cabeçalho de um objeto livre do alocador do Cache Comprimido -- xvMalloc.}
	\label{fig:obj-free}
\end{figure}

Na figura \ref{fig:obj-free}, existem campos que apontam para a próximo e o anterior endereços de página. Esses campos são utilizados para acessar rapidamente uma página quando é requisitada pelo kernel do Linux. Cada página é identificada pela tupla \textit{<pageNum, offset>}.

\subsubsection{Operações de Inserção e Remoção das Páginas Comprimidas}

\textbf{Inserção de páginas no Cache Comprimido:} a página descomprimida é primeiramente comprimida numa página de \textit{buffer}. O algoritmo de compressão utilizado é o LZO \cite{obe05lzo, ZivLem77}, que já é utilizado em sistemas de arquivo do Linux que utilizam compressão.  Após a compressão, o Cache Comprimido requisita ao ramzswap que armazene a página, sendo $\omega$ o tamanho da página comprimida. Nesse momento, o ramzswap solicita ao alocador xvMalloc que aloque um espaço de memória de tamanho $\omega$. Por fim, o xvMalloc passa ao ramzswap a tupla <pageNum, offset> como identificador daquela página. Essa tupla substitui o endereço no nodo da radix tree que o PFRA gerencia.

\begin{figure}[htb]
	\centering
	\includegraphics[scale=0.6]{radix_tree}
	\caption{Radix tree padrão, antes da compressão da página.}
	\label{fig:radix-tree}
\end{figure}

\textbf{Remoção de páginas do Cache Comprimido:} do ponto de vista do PFRA e do kernel, a página comprimida tem o mesmo tipo que uma página normal. A única diferença entre a página comprimida e as páginas normais é que, a primeira está armazenada em uma partição de swap chamada ramzswap. Dessa forma, a referência à pagina comprimida, que é passada para a radix tree não se difere da referência das outras páginas, pois o ramzswap é um dispositivo de bloco como os outros. Assim, fica à cargo do Cache Comprimido e do xvMalloc que encontre a página comprimida, descomprime-a e retorne sua referência e valor ao kernel quando o mesmo requisita uma página do ramzswap.

\section{Experimentos}

Nesta seção são apresentados os testes que foram executados utilizando Cache Comprimido em um sistema embarcado com Linux. O principal objetivo dos testes é avaliar os impactos e as características do consumo de memória, quando temos uma área comprimida adicionada ao sistema.\\

Como dito anteriormente, a atual implementação do Cache Comprimido trata dois tipos de páginas: páginas anônimas e páginas do \textit{Page Cache}. O primeiro tipo de páginas foi utilizado como referência pois pode ser feito \textit{swap}, facilitando a obtenção de dados para os gráficos.\\

Foram realizados testes com e sem um \textit{swap} real, utilizando uma partição em um cartão MMC\footnote{Os cartões MMC são utilizados como memória secundária de dispositivos móveis, câmeras fotográficas, etc. Cartões MMC possuem uma taxa de transferência de até 52 MB/seg. A capacidade de armazenamento varia de alguns \textit{megabytes} até cartões com mais espaço de armazenamento, na ordem de \textit{gigabytes}.}. A utilização de um \textit{swap} real se justifica pois é importante comparar o \textit{swap} virtual com o real. Como medidas desta comparação, foram considerados os seguintes itens:

\begin{itemize}
	\item  Quantas páginas são mantidas no Cache Comprimido e não vão para o \textit{swap} real, evitando assim um maior \textit{overhead} por causa das operações de E/S.
	\item Em quais situações o Cache Comprimido é útil para evitar que o OOM (Out-of-memory killer), seja chamado.
	\item Qual é a velocidade para que páginas de memória sejam comprimidas e armazenadas no ramzwap.
\end{itemize}

\subsection{Suite de Testes e Metodologia}

Utilizou-se um dispositivo móvel, parecido com um PDA que possui Linux embarcado como sistema operacional nativo. O Nokia Internet Tablet N810 \cite{nokiaN810} tem um processador ARM1136 com 400Mhz, 128MB de memória RAM e 256MB de memória \textit{flash}, utilizada como armazenamento secundário. Ainda possui acelerador gráfico 2D/3D e dois leitores de cartões MMC/SD.\\

Nota-se que este dispositivo móvel, como muitos outros, foi projetado para aplicações multimídia \cite{nokiaN810}. Este tipo de aplicação demanda muito poder de processamento e quantidade de memória razoável para as aplicações. Levando isso em consideração, os testes foram realizados afim de verificar o comportamento de todo o sistema e das aplicações multimídia, quando a quantidade de memória livre disponível é muito baixa. O objetivo é verificar a performance de todo o sistema, quando se realizam operações de compressão e recuperação das páginas comprimidas.\\

Os casos de uso dos testes podem ser divididos em duas partes: testes que utilizam \textit{benchmarks} sintéticos e testes que simulam a utilização real do aparelho. No primeiro grupo, existe um maior controle do consumo de memória e assim, pode-se avaliar o comportamento do Cache Comprimido quando é submetido à pressões por falta de memória. No segundo grupo, foi verificado se o Cache Comprimido exerce um \textit{overhead} que afeta a performance das aplicações que o usuário pode executar. Espera-se que a performance das aplicações melhore, visto que o número de E/S resultantes de acessos à um dispositivo de \textit{swap} real (dispositivo de bloco), é diminuído pois mais páginas se encontram na memória principal, através do \textit{swap} virtual utilizando o ramzswap..\\

Os testes utilizando aplicações, consistem em:

\begin{itemize}

	\item Executar de 8 a 10 instâncias do navegador WEB, simultaneamente, acessando páginas na Internet através de uma conexão de rede sem-fio.
	\item Tocar um arquivo de vídeo de 7,5MB.
	\item Realizar operações com mídias: tocar mp3, indexar novos arquivos, abrir fotos, etc.
	\item Abrir um documento em formato PDF.
\end{itemize}

Para fazer a interação entre o \textit{X system} e as aplicações, foi utilizado uma ferramenta chamada Xautomation \cite{xauto07}. Com esta ferramenta foi possível controlar toda a movimentação do cursor na tela e os cliques. Enquanto as aplicações são executadas, outros programas ficam responsáveis de fazer a coleta das informações referentes ao consumo de memória, através de leituras das estatísticas exportadas pelo \texttt{procfs}. É com base nesses dados que alguns gráficos foram plotados e discutidos nas seções posteriores deste trabalho.\\

Os testes utilizando \textit{benchmarks} sintéticos, foram executados usando um conjunto de utilitários chamado MemTest \cite{memtest06}. MemTest foi implementado para avaliar a estabilidade e consistência do sistema de gerência de memória do Linux \textit{kernel}. Do MemTest foi utilizado um utilitário chamado \texttt{fillmem}. Este utilitário faz várias alocações de memória, ou seja, de páginas de memória, disparando a necessidade de mandar algumas páginas para o ramzswap, ou seja, o \textit{swap} virtual.

Ambos os tipos de testes, utilizaram cenários pré-definidos, dependendo do que se queria medir. Basicamente, os cenários apresentavam diferentes tamanhos da memória principal, se possuíam uma área de \textit{swap} real ou não, ou se estavam com o Cache Comprimido habilitado ou não.\\

Os testes de comportamento do consumo de memória visam avaliar como a memória é consumida ao longo do tempo de duração do teste. Assim, espera-se identificar os pontos de falta de memória e a atuação do OOM \textit{killer}. Como o Cache Comprimido se utiliza da memória principal para armazenar as páginas comprimidas no \textit{swap} virtual, a quantidade de memória não-comprimida disponível para as aplicações é decrescida, e isso pode levar a uma chamada precoce do OOM killer.

\subsubsection{Ajustando o kernel}

Antes dos testes serem iniciados, alguns parâmetros do gerenciamento de memória do \textit{kernel} devem ser ajustados, afim de garantir que os testes sejam executados com sucesso.\\

O sistema de \textit{swap} do \textit{kernel} possui alguns parâmetros que podem interferir nos valores medidos, e até na execução das aplicações. Durante os testes, foram alterados dois desses parâmetros:

\begin{itemize}
\item \textbf{swappiness} \cite{love05kerneldevel} é um parâmetro que conFigura um fator de balanço que o \textit{kernel} utiliza para manter mais ou menos páginas no \textit{Page Cache} antes de mandar para a área de \textit{swap}. Seu valor \textit{default} é 60.
\item \textbf{min\_free\_kbytes} \cite{love05kerneldevel} é usado como um limite mínimo de memória livre para que o sistema de gerenciamento de memória virtual do \textit{kernel} comece a mandar páginas para o \textit{swap}.
\end{itemize}

Se o usuário quer que o \textit{kernel} mande mais páginas para o \textit{swap}, o que significa em mais páginas comprimidas, quando o CC está rodando com o \textit{swap} virtual, o parâmetro \texttt{swappiness} deve ser acrescido. Uma outra forma de mandar as páginas mais cedo para o \textit{swap}, é aumentar o valor do \texttt{min\_free\_kbytes}. Durante os testes, foram utilizados valores diferentes desses dois parâmetros em cada cenário, afim de prover diferentes situações de falta de memória.\\

Existem outros parâmetros que também devem ser ajustados, mas que não fazem parte do \textit{kernel} padrão. São os parâmetros que conFiguram o tamanho do Cache Comprimido para as páginas anônimas e as páginas do \textit{Page Cache}. Os parâmetros são os seguintes:

\begin{itemize}
 \item \texttt{max\_fs\_backed\_cc\_size:} este parâmetro é utilizado para conFigurar o tamanho máximo do CC para páginas que pertencem ao \textit{Page Cache}.
\item \texttt{max\_anon\_cc\_size:} este parâmetro é encarregado de conFigurar o tamanho máximo do Cache Comprimido para páginas anônimas, ou seja, o \textit{swap} virtual.
\end{itemize}

Vale ressaltar que os valores que devem se escritos nesses parâmetros estão na unidade de quantidade de páginas de memória, neste trabalho é utilizado o tamanho padrão de \texttt{PAGE\_SIZE = 4KB}.

\subsection{Testes do Comportamento do Consumo de Memória}
\label{sec:mem_behavior}

O principal objetivo deste tipo de teste é visualizar como a memória é consumida ao longo do tempo e as situações de falta da mesma, quando várias aplicações são executadas pelo usuário. Para realizar estes testes, foram utilizados cenários que simulassem a interação do usuário no ambiente gráfico.\\

Foi desenvolvido um programa que automatiza a interação com as aplicações gráficas Usando o XAutomation \cite{xauto07}. Enquanto as aplicações eram executadas, um outro programa fazia leituras no \texttt{procfs}, coletando informações sobre a memória consumida por processo ou total do sistema.\\

%A Figura \ref{fig:memtest01} mostra o consumo de memória através do tempo com o \texttt{max\_anon\_cc\_size} conFigurado para 1024 páginas (ou 4MB de tamanho).

%\begin{figure}[htb]
%	\centering
%	\includegraphics[scale=0.80]{mem_behavior01}
%	\caption{Tamanho do Comp. Cache x tempo: max\_anon\_cc\_size = 1024, Mem = 128M}
%	\label{fig:memtest01}
%\end{figure}

%Como pode-se notar na Figura \ref{fig:memtest01}, o consumo da área reservada para as páginas comprimidas foi inexistente. Nota-se pela linha de cor verde paralela ao eixo $X$ do gráfico, que representa o consumo do CC ao longo do tempo. O tamanho do CC se manteve estável ao longo do tempo, mostrando que nenhuma página foi comprimida. Isso se deve ao fato do \textit{kernel} estar conFigurado para reter mais páginas na memória, ou seja, na área descomprimida antes de enviá-las ao \textit{swap}. Esta implementação do CC \cite{briglia07, ccache09} se aproveita do sistema de \textit{swap} para comprimir as páginas, armazenandos-as em uma área de \textit{swap} virtual. Se o \textit{kernel} estiver conFigurado com parâmetros para diminuir a utilização das áreas de \textit{swap}, é evidente que afetará a utilização do CC, já que o mesmo segue conFigurações passadas para o \textit{kernel}. Na Figura \ref{fig:memtest02}, a memória RAM foi limitada para somente 100 MB, ao invés de 128 MB. Este valor de 100MB foi calculado com base em alguns testes empíricos. O tamanho da memória RAM total afeta os testes pois está diretamente aliada às condições de falta de memória. A memória total foi alterada para que a utilização do CC fosse maior. Porém, na Figura \ref{fig:memtest02}, pode-se notar que o OOM \textit{killer} foi invocado no tempo 600 ms. O CC foi utilizado (linha verde do gráfico), porém não teve tamanho suficiente para alocar uma quantidade de páginas comprimidas que satisfizessem a rápida alocação de memória imposta pelo teste. Dessa forma, a memória livre total (\textit{MemFree}, linha vermelha no gráfico), chegou à zero e o OOM \textit{killer} foi chamado para terminar algumas aplicações, liberando assim memória para o sistema (note que a linha vermelha de \textit{MemFree} sobe consideravelmente após a chamada do OOM).\\

%\begin{figure}[htb]
%	\centering
%	\includegraphics[scale=0.80]{mem_behavior02}
%	\caption{Cache Comprimido x tempo: max\_anon\_cc\_size = 1024, Mem = 100M}
%	\label{fig:memtest02}
%\end{figure}

%Usando o mesmo teste, mas com \texttt{swappiness = 60} e \texttt{min\_free\_kbytes = 3072}, o OOM \textit{killer} não foi invocado e o Cache Comprimido finalmente foi bastante utilizado. Veja na Figura \ref{fig:memtest03}.\\

%\begin{figure}[htb]
% 	\centering
% 	\includegraphics[scale=0.80]{mem_behavior03}
% 	\caption{Cache Comprimido x tempo: swappiness = 60, min\_free\_kbytes = 3072}
% 	\label{fig:memtest03}
%\end{figure}

%A Figura \ref{fig:memtest03} mostra que o CC não é suficiente para a carga de memória imposta pelo teste. Seria necessário aumentar o seu tamanho, porém, tem-se um problema aqui: se o tamanho do CC for muito grande (mais de 50\% da memória total, por exemplo), não restará muita memória livre para as outras operações do \textit{kernel}, uma vez que o \textit{swap} virtual utiliza páginas da memória RAM. Uma das possíveis soluções para este problema é a implementação de um esquema de adaptabilidade do tamanho do Cache Comprimido \cite{castro03, irina05}.\\

%Durante os testes, o tamanho das páginas comprimidas foi coletado afim de verificar qual é o tamanho médio de uma página depois de comprimida. Como pode-se ver na Figura \ref{fig:cc_dist}, a maioria das páginas ficam com metade do tamanho original depois de comprimidas. Mais ou menos 42\% das páginas ficam com tamanho entre 1 Kb e 2 Kb, depois da compressão. Esses valores dependem do algoritmo de compressão utilizado. Neste teste foi utilizado o algoritmo WK4x4, proposto em \cite{kaplan99compressed, wilson99}.\\

%\begin{figure}[htb]
%	\centering
%	\includegraphics[scale=0.65]{cc_distribution}
%	\caption{Distribuição do tamanho das páginas comprimidas}
%	\label{fig:cc_dist}
%\end{figure}

%Os resultados destes testes indicam que tem-se um ganho na memória disponível para as aplicações quando o CC é utilizado. Com a fragmentação controlada através da abordagem de \textit{chunks}, e com a maioria das páginas comprimidas ficando com o tamanho entre 1 Kb e 2 Kb, pode-se chegar à conclusão que o CC aumenta em 100\% a memória disponível para as aplicações, através da compressão e utilização do \textit{swap} virtual. Esta é uma vantagem importante pois aplicações que antes não poderiam ser executadas por falta de memória, agora podem se beneficiar de uma memória virtualmente maior. Uma conclusão idêntica foi encontrada em \cite{irina05}, utilizando outra versão de Cache Comprimido.\\

%Um dos problemas encontrados é que o \textit{kernel} deve ser bem ajustado para o uso do CC. Se isso não acontecer, o \textit{swap} virtual não é utilizado e as páginas não são comprimidas. Como as páginas reservadas ao Cache Comprimido nunca são liberadas pelo PFRA, seu tamanho pode diminuir a memória disponível para as aplicações, acarretando em constantes invocações do OOM \textit{killer}.

\subsection{Testes de Performance}

Nesse tipo de teste foi utilizado um \textit{benchmark} sintético que realize a alocação de uma grande área de memória. O objetivo é analisar o overhead imposto pelo Cache Comprimido quando as páginas são destinadas à área de \textit{swap} virtual (ramzswap).\\

Para testar a alocação de memória, foi utilizado um programa da suíte de testes MemTest\cite{memtest06}. O programa em questão é o \textbf{fillmem} e ele foi usado para alocar uma grande quantidade de memória de forma muito rápida. Na figura \ref{fig:fillmem50} estão os tempos de execução do fillmem para alocar 50 MB de memória.\\

\begin{figure}[htb]
 \centering
 \includegraphics[scale=0.5]{fillmem50.png}
 % fillmem50.png: 640x480 pixel, 72dpi, 22.58x16.93 cm, bb=0 0 640 480
 \caption{Tempo de de execução do fillmem para alocar 50 MB.}
 \label{fig:fillmem50}
\end{figure}

No gráfico mostrado na figura \ref{fig:fillmem50}, nota-se que o tempo de alocação do fillmem é cerca de três vezes maior quando se usa o Cache Comprimido. Isso deve-se ao fato de haver overheads para a compactação das páginas. Apesar disso, quando Cache Comprimido é comparado à um sistema de \textit{swap} real, ou seja, utilizando um dispositivo de bloco real e não o ramzswap, nota-se que o tempo é bem maior quando se trata de escritas no MMC.

\chapter{Redes Neurais e Mapas Auto-organizáveis}

Este capítulo apresenta o esquema de classificação de padrões de consumo de memória desenvolvido em \cite{Mlin:06} e como essa metodologia poderá ajudar na implementação da adaptatividade do tamanho do Cache Comprimido proposto neste trabalho.

\section{Redes Neurais e Mapas Auto-organizáveis}
\label{sec:redes_artificiais}

As \textit{redes neurais artificiais} consistem em um método para solucionar problemas de inteligência artificial, armazenando um conhecimento experimental do problema atrav\'{e}s de t\'{e}cnicas de treinamento.\\

As redes neurais podem ser definidas como um grupo interconectado de neurônios artificiais que usa um modelo matemático ou computacional baseado no comportamento do cérebro humano para processamento de informações \cite{Haykin:99, Christos, Tatibana}. Uma rede neural é capaz de extrair regras básicas a partir de dados reais, ou seja, a sistemática do problema, diferindo assim da computação programada, onde é necessário um conjunto de regras rígidas pré-fixadas e algoritmos \cite{Haykin:99}.\\

Existem duas abordagens de treinamento para as redes neurais: o supervisionado e o não-supervisionado \cite{Haykin:99}.\\

Independente do tipo de aprendizagem ou treinamento selecionado, toda rede é alimentada por uma seqüência de valores $x_{1}, x_{2}, \cdots, x_{n}$ na entrada e os pesos são ajustados de acordo com um modelo matemático durante a fase de treinamento. O processo de treinamento pode ser organizado nas etapas seguintes \cite{Haykin:99}:

\begin{enumerate}
	\item O primeiro padrão de entrada é apresentado para a rede.
	\item Os pesos são ajustados para capacitar a rede de reconhecer o padrão fornecido.
	\item O segundo padrão de entrada é apresentado para a rede e a etapa 2 é efetuada novamente.
	\item O mesmo é aplicado para todos os outros padrões.
	\item O procedimento de 1 até 4 é executado novamente centenas ou milhares de vezes até encontrar uma conFiguração de pesos sinápticos capaz de reconhecer todos os padrões fornecidos no treinamento.
\end{enumerate}

\subsection{Mapas Auto-Organizáveis}
\label{sec:som}

\textit{Mapas Auto-Organizáveis} ou simplesmente \textit{SOM (do inglês Self Organizing Maps)} é uma rede neural artificial auto-organizável, de aprendizagem não supervisionada, baseada em grades de neurônios artificiais onde os pesos são adaptados em conformidade com os vetores de entrada fornecidos durante o treinamento. Foi desenvolvido pelo professor Teuvo Kohonen e às vezes é chamado de mapa de Kohonen \cite{Junkie, Borgelt:00, Germano:99, Honkela:98, Koh88}.\\

No SOM, os neurônios estão colocados em nós de uma grade unidimensional ou bidimensional, outras dimensões tamb\'{e}m s\~{a}o possíveis, embora n\~{a}o sejam t\~{a}o comuns. Os neurônios são seletivamente sintonizados a vários padrões de entrada ou classes de padrões de entrada no decorrer de um processo de aprendizagem ou treinamento.\\

As localizações dos neurônios assim sintonizados se tornam ordenadas entre si de modo que um sistema de coordenadas significativas para características diferentes de entrada é criado sobre a grade. Portanto um mapa auto-organizável é caracterizado pela formação de uma mapa topográfico dos padrões de entrada, baseado nas características estatísticas intrínsecas contidas nos padrões de entrada, por isso o nome \textit{mapa auto-organizável} \cite{Haykin:99}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.30\textwidth]{training}
	\caption{Exemplo de rede n\~{a}o treinada.\cite{Mlin:06}}
	\label{fig:training}
\end{figure}

Um exemplo comum usado para mostrar os princípios de SOM é o mapeamento de cores a partir de seus 3 componentes: vermelho, verde e azul ou RGB (\textit{red, green and blue}) em um espaço bidimensional. A Figura \ref{fig:som_demo} ilustra um exemplo de SOM treinado para reconhecer padrões de cores RGB. As cores são fornecidas para a rede como vetores de 3 dimensões, uma dimensão para cada componente de cor, e a rede foi treinada para representá-los em um espaço de 2 dimensões. Observe que além do agrupamento de cores em regiões distintas, as regiões de propriedades similares estão localizadas de forma adjacente.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.30\textwidth]{som_demo}
	\caption{Um exemplo de SOM treinado para classificação de cores.\cite{Mlin:06}}
	\label{fig:som_demo}
\end{figure}

A rede SOM ilustrada na Figura \ref{fig:som_demo} apresenta uma grade de tamanho $40 \times 40$. Cada nó da grade possui 3 pesos, cada um representando um componente RGB. Além disso, cada nó é representado por uma célula retangular, quando desenhado na interface gráfica do aplicativo.\\

Cada nó da grade tem uma posição topológica específica representada por uma coordenada $(x, y)$ e contém um vetor de pesos sinápticos de dimensão igual ao vetor de entrada. Ou seja, caso os dados de treinamento consistem de vetores $x$ de dimensão $n$:\[ x = [x_{1}, x_{2}, x_{3}, ..., x_{n}] \] Então cada nó ou neurônio $j$ da grade contém um vetor correspondente de peso $w_{j}$ com a mesma dimensão $n$:

\[ w_{j} = [w_{j1}, w_{j2}, w_{j3}, ..., w_{jn}] \]

A formação do SOM \'{e} feita primeiramente inicializando os pesos sinápticos da grade, com valores obtidos de um gerador de números randômicos. Assim, nenhuma organização prévia é imposta ao mapa de características (veja Figura \ref{fig:training}. Depois que a grade \'{e} feita, s\~{a}o executados 6 processos importantes \cite{Haykin:99}:

\begin{description}
	\item[Inicialização:] Cada neurônio tem os seus pesos sinápticos inicializados aleatoriamente. Geralmente os pesos são inicializados entre 0 e 1, ou seja, $0 < w < 1$.
	\item[Seleção de Vetor de Entrada:] Um vetor de entrada é escolhido do conjunto de dados de treinamento e apresentado para a grade de neurônios.
	\item[Competição de Neurônios:] Todos os pesos de todos os neurônios são calculados para determinar o neurônio mais semelhante em relação ao vetor de entrada. O neurônio mais semelhante \'{e} selecionado e é considerado como o neurônio vencedor é chamado de Unidade de Melhor Casamento ou BMU (do \textit{inglês Best Matching Unit}).
	\item[Cooperação de Neurônios:] O \textit{raio da vizinhança topológica} do BMU é calculado. O valor do raio assume inicialmente um valor elevado, geralmente tem o mesmo raio da grade, mas diminui a cada iteração do treinamento. Os neurônios localizados dentro deste raio são considerados os vizinhos do BMU.
	\item[Adaptação Sináptica:] Os pesos sinápticos de cada neurônio vizinho do BMU são ajustados para torná-los similares ao vetor de entrada. Os neurônios vizinhos mais próximos do BMU têm os seus pesos alterados de modo mais significativo.
	\item[Repetição:] O segundo passo é retomado novamente selecionando um novo vetor de entrada e os passos subseqüentes são então executados.
\end{description}

A forma para determinar o BMU é acessar todos os neurônios da grade e calcular a \textit{distância Euclidiana} entre o vetor peso de cada neurônio e o vetor de entrada atual. O neurônio de vetor peso mais próximo do vetor de entrada (menor distância Euclidiana), é considerado como o neurônio vencedor ou BMU. Neste caso a distância Euclidiana é a função discriminante neste processo competitivo de neurônios e calculado como ilustra a Equação \ref{eq:euclidean}.

\begin{equation}
dist_{j} = \sqrt{\sum_{i=1}^n (x_{i}-w_{i})^2}
\label{eq:euclidean}
\end{equation}

A cada iteração do treinamento, após o BMU ter sido determinado, o passo seguinte consiste em calcular quais são os neurônios localizados na vizinhança topológica do BMU. Tais neurônios terão os seus pesos sinápticos alterados posteriormente durante o processo de adaptação sináptica. A Figura \ref{fig:bmu} ilustra um exemplo de vizinhança topológica determinada no início do treinamento da rede.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.30\textwidth]{bmu}
	\caption{Vizinhança topológica de um BMU representada pela área sombreada\cite{Mlin:06}.}
	\label{fig:bmu}
\end{figure}

Uma característica da rede SOM é que a área da vizinhança topológica diminui ao longo do treinamento da rede.  A cada iteração $t$, a função de decaimento exponencial é calculada para permitir o reajuste do tamanho da vizinhança do BMU como mostrada na Equação \ref{eq:decay}:

\begin{equation}
\sigma(t) = \sigma_{0} e^{(-\frac{t}{\lambda})}
\label{eq:decay}
\end{equation}

onde $\sigma_{0}$ representa o raio $\sigma$ no tempo $t_{0}$ que tem o mesmo valor do raio da grade, e $\lambda$ é uma constante de tempo. A variável $t$ representa um dado instante do treinamento, ou melhor, um passo de tempo da iteração.

\subsection{Classificação de Padrões de Consumo de Memória baseado em Redes Neurais Auto-Organizáveis}
\label{sec:classe_rede}

Ainda baseado em \cite{Mlin:06}, essa seç\~{a}o mostra um pouco dos testes realizados afim de classificar padrões de consumo de memória utilizando um SOM.
Os testes consistem em executar casos de uso de aplicações afim de realizar algumas medições do consumo de memória das aplicações envolvidas. Os casos de uso foram executados no sistema operacional Linux.
Após a execuç\~{a}o de alguns casos de uso, foram observadas várias variáveis afim de compor os dados de entrada para o algoritmo de SOM. A seguinte estrutura foi escolhida para representar os dados de entradas:

\begin{itemize}
\item quantidade de páginas físicas alocadas que representa a \textit{quantidade de memória física consumida};

\item \textit{variação do consumo de memória (VCM)} que é utilizada para indicar o ritmo em que o consumo de memória está aumentando ou diminuindo. Esta variação é calculada através da razão entre a diferença da quantidade de memória física consumida e o intervalo de tempo decorrido, conforme a Equação \ref{eq:velocidade};

\begin{equation}
VCM = \frac{mem_{2} - mem_{1}}{t_{2} - t_{1}}
\label{eq:velocidade}
\end{equation}

\item \textit{taxa de variação do consumo de memória (TVCM)} que é utilizada para indicar o ritmo em que a variação de consumo de memória está aumentando ou diminuindo. Esta taxa é calculada através da razão entre a diferença da variação do consumo de memória e o intervalo de tempo decorrido, conforme a Equação \ref{eq:aceleracao}.
\end{itemize}

\begin{equation}
TVCM = \frac{vcm_{2} - vcm_{1}}{t_{2} - t_{1}}
\label{eq:aceleracao}
\end{equation}

Os seguintes estados podem ser atribuídos para cada propriedade apresentada: Low (L), Medium (M) e High (H). Os estados L, M e H representam respectivamente um conjunto de números pequenos, médios e grandes em um intervalo de valores estabelecidos. A definição de L, M e H são usadas para representar o comportamento de uma determinada propriedade de uma forma simples e abstrata.\\

Assumindo que os valores para uma determinada propriedade está em um intervalo positivo $[limite_{minimo}, limite_{maximo}]$, então o mesmo pode ser dividido em 3 subintervalos que representam os estados \textit{L}, \textit{M} e \textit{H}, como ilustrado na Figura \ref{fig:lmh}. Observe que os valores de L, M e H são dependentes do limite mínimo e máximo de um intervalo estabelecido.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.40\textwidth]{lmh}
	\caption{Subintervalos que representam os estados \textit{Low (L)}, \textit{Medium (M)} e\textit{ High (H)}.}
	\label{fig:lmh}
\end{figure}

A quantidade de memória consumida está localizada em um desses subintervalos, assumindo um dos três estados $\{Low, Medium, High\}$ apresentados. Sendo assim a quantidade de memória consumida é classificada como \textit{baixo consumo} de memória quando o seu valor está no estado L, \textit{médio consumo} de memória quando o seu valor está no estado M e \textit{alto consumo} de memória quando localizado no estado H. A quantidade de memória consumida abrange somente valores inteiros positivos, visto que consumo de memória de valor negativo é logicamente inexistente no mundo real. A mesma analogia \'{e} utilizada para os valores de VCM e TVCM.\\

A tripla $<$memória,vcm,tvcm$>$ pode ser mapeada facilmente para uma estrutura de dados que seja aceita algoritmo do SOM, que foi desenvolvido em \cite{Mlin:06}. Já que o SOM utiliza vetores tridimensionais como valores de entrada, a tripla pode facilmente ser calculada contendo cada valor como sendo uma dimens\~{a}o desse vetor.\\

Cada vetor no espaço tridimensional é uma instância específica da tripla que é mapeado na grade de neurônios do SOM. Cada célula da grade de neurônios armazena então um vetor tridimensional do tipo [memória, vcm, tvcm], conforme a Figura \ref{fig:mapeia}.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.55\textwidth]{mapeia}
	\caption{Os vetores são mapeados em um espaço bidimensional representado pela grade de neurônios.}
	\label{fig:mapeia}
\end{figure}

A idéia de utilizar o mapa de neurônios auto-organizáveis é agrupar topologicamente as classes apresentadas de consumo de memória em áreas ou regiões distintas. Dessa forma, cada região representa uma conFiguração ou conjunto de conFigurações similares capaz de representar o estado do consumo de memória em um determinado instante.\\

Para treinar a rede, utilizou-se um caso de uso que tentava reproduzir o uso normal de um computador. Neste caso de uso foram utilizadas v\'{a}rias aplicações gr\'{a}ficas como: browsers, leitores de pdf, video players e editores de texto.

\section{Resultados obtidos}

Após a rede neural ter sido treinada, o mapa topológico do SOM \'{e} mostrado na Figura \ref{fig:som_treinado}:

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.35\textwidth]{som_treinado.png}
	\caption{Rede Neural Treinada com dados coletados em Linux Embarcado \cite{Mlin:06}.}
	\label{fig:som_treinado}
\end{figure}

O treinamento da rede neural foi feito utilizando um caso de uso gen\'{e}rico como dito anteriormente, desenvolvido para Linux embarcado por Francisco Alecrim \cite{Alecrim:07}. Ainda no trabalho desenvolvido em \cite{Alecrim:07}, encontramos uma ferramenta desenvolvida para analisar de uma forma mais intuitiva e melhorada os mapas topográficos das aplicações individualmente. Desta forma, \'{e} possível classificar cada caso de uso em relaç\~{a}o aos valores da tripla [memória consumida, vcm, tvcm].\\

Na ferramenta desenvolvida, foi adicionado mais um dado referente à freqüência da área que o BMU acessa no mapa do caso de uso geral (Veja Figuras \ref{fig:pdf_viewer}, \ref{fig:browser_1} e \ref{fig:browser_2}. O box central da interface, mostra os nós mais acessados pelo caso de uso que está sendo analisado. Quanto mais escuro, mais vezes aquele nó foi visitado, ou seja, escolhido como BMU. Esse \'{e} um dado muito importante pois permite que seja visualizado melhor as características de alocaç\~{a}o de memória do caso de uso.\\

Na Figura \ref{fig:pdf_viewer}, pode-se notar que o caso de uso executado para a aplicaç\~{a}o \textbf{PDF Viewer} possui um escurecimento mais intenso nas regiões de coloraç\~{a}o azul. A cor azul representa a característica de padr\~{a}o de consumo m\'{e}dio.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.7\textwidth]{pdf_viewer.png}
	\caption{Resultados obtidos com o cenário 3 utilizando o aplicativo PDF Viewer.\cite{Alecrim:07}}
	\label{fig:pdf_viewer}
\end{figure}

Nas Figuras \ref{fig:browser_1} e \ref{fig:browser_2}, encontram-se os mapas para a aplicaç\~{a}o \textbf{Browser}. No cenário 1, onde utilizada uma única aba para a navegaç\~{a}o, o aplicativo alternou entre o padr\~{a}o de consumo alto e m\'{e}dio,com m\'{e}dia variaç\~{a}o de consumo de memória e baixa taxa de variaç\~{a}o de consumo. No cenário 2, onde s\~{a}o utilizadas várias janelas para navegaç\~{a}o, o aplicativo teve padr\~{a}o do consumo alto, com baixa variaç\~{a}o e taxa de variaç\~{a}o.

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.7\textwidth]{browser_1.png}
	\caption{Resultados obtidos com o cenário 1 utilizando o aplicativo Browser.\cite{Alecrim:07}}
	\label{fig:browser_1}
\end{figure}

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.7\textwidth]{browser_2.png}
	\caption{Resultados obtidos com o cenário 2 utilizando o aplicativo Browser.\cite{Alecrim:07}}
	\label{fig:browser_2}
\end{figure}

\section{Utilização de SOM na adaptatividade do Cache Comprimido}
Como proposto nesta dissertação, a utilização da ferramenta desenvolvida em \cite{Alecrim:07} e \cite{Mlin:06}, é bastante útil na implementação da adaptatividade do CC. Utilizando os mapas gerados pela análise de cada aplicação, pode-se avaliar em quais momentos é necessário que o tamanho do CC seja alterado afim de suprir a necessidade de memória livre do sistema.\\

Com a criação de um mapa com casos de uso que simulem a utilização do sistema por um usuário final, é possível determinar quais são as áreas mais acessadas por determinadas aplicações. Nesse caso, é possível verificar qual é o comportamento de consumo de memória para um determinado caso de uso e assim, tomar medidas para que não falte memória. Essas medidas podem ser o aumento ou diminuição do tamanho do CC, a mudança para um algoritmo de compressão mais eficaz (porém mais lento), etc. A tripla $<$memória, vcm, tvcm$>$, pode ser utilizada para "prever" o consumo de memória baseado no consumo anterior e no perfil (mapa) da aplicação analisada. O parâmetro "tvcm" é especialmente importante pois pode ser utilizado como a "velocidade" que uma aplicação aloca mais memória. Muito útil para evitar que situações que o OOM \textit{killer} seja invocado.

%\chapter{Conclusão}
%\section{Conclusão}
%Armazenar páginas de memória em formato comprimido pode diminuir o número de acessos à dispositivos de bloco, como por exemplo, discos-rígidos, que são mais lentos que a memória RAM. Os benefícios de um sistema com Cache Comprimido são mais evidentes quando a diferença de velocidade de acesso entre a área de \textit{swap} e a memória RAM são maiores.\\

%Utilizando uma área de \textit{swap} na memória mostrou-se uma boa técnica para armazenar mais páginas em menos espaço. Porém, os metadados continuam sendo um problema, assim como a localização de páginas comprimidas. Utilizando a abordagem de \textit{chunks}, a fragmentação é diminuída porém o custo de manter as estruturas para também é alto. Apesar disso, os \textit{overheads} impostos pelo uso do CC foram superados pelo benefícios que a compressão provê. Aplicações que possuem um \textit{working set} muito grande, podem ser beneficiadas com o uso da memória comprimida pois a memória é virtualmente incrementada, deixando mais espaço para as aplicações.\\

%As Redes Neurais s\~{a}o uma t\'{e}cnica poderosa para a classificaç\~{a}o de padrões. Por\'{e}m, o grande desafio está na representaç\~{a}o dos dados do problema de uma forma que seja possível serem mapeados em um mapa topológico.\\

%Uma classificaç\~{a}o dos padrões de consumo de memória das aplicações pode ser muito útil para melhorar a política de alocaç\~{a}o de memória encontrada atualmente no núcleo (ou \textit{kernel}) do Linux. Todavia, por precisar de um grande volume de dados de entrada, esta t\'{e}cnica \'{e} totalmente inviável para ser utilizada \textit{on-the-fly}, ou seja, durante a execuç\~{a}o do sistema. Como um trabalho futuro, o que pode ser realizado \'{e} a busca de um algoritmo que leve em conta mapas j\'{a} reconhecidos de alguma forma. Desta forma poderia ser possível predizer o comportamento do consumo de memória, e com isso utilizar diferentes políticas afim de garantir a integridade do sistema.\\

\addcontentsline{toc}{section}{Referências}
%\bibliographystyle{alpha}
%\newpage

\begin{flushleft}
	\bibliography{briglia-ref}
	\bibliographystyle{plain}
\end{flushleft}

\end{document}
